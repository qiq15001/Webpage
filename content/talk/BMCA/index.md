---
title:  A Multi-Stage Stochastic Model in the Analysis of Longitudinal Data
event: Conference on Bayesian Modeling, Computation and Applications 2018

location: University of Connecticut
address:
  street: 363-367 Fairfield Way
  city: Storrs
  region: CT
  postcode: '06279'
  country: United States


abstract: Multi-stage transition model is playing an important role in dementia studies. Since death is a significant source of missing data in longitudinal epidemiological studies on elderly individuals, we consider four stages: normality, memory-impaired intermediate, dementia and death without dementia. To analyze longitudinal data, we develop the likelihood function based on a first order Markov chain model consisting of transitional probabilities between stages. Different from the typical illness-death model, we construct a reversible transition model between normality and memory-impaired intermediate. We use Kolmogorovâ€™s backward equations to derive the probability of transition and ordinal logistic regression to investigate what covariates have significant influence on the transition.

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2018-05-12T15:00:00Z"
date_end: "#"
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: "2019-10-29T00:00:00Z"

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: false


# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
- c-project

# Enable math on this page?
math: false
---




